{
	"name": "sweden_medicalNB",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "group3fpspark",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "198e1b48-59ad-4e52-8430-0407511d62b7"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/23b183d5-a30f-46b8-b418-ad060fb67787/resourceGroups/group3fp/providers/Microsoft.Synapse/workspaces/group3fpsynapse/bigDataPools/group3fpspark",
				"name": "group3fpspark",
				"type": "Spark",
				"endpoint": "https://group3fpsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/group3fpspark",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"\n",
					"\n",
					"import os, time, glob\n",
					"import pandas as pd, requests\n",
					"from urllib.parse import quote\n",
					"\n",
					"BASE = \"https://sdb.socialstyrelsen.se/api/v1/sv/lakemedel\"\n",
					"HEADERS = {\"User-Agent\":\"synapse-a10/1.0\",\"Accept\":\"application/json\"}\n",
					"MATT_PAT, MATT_EXP = 1, 3               # 1=Antal patienter, 3=Antal expedieringar\n",
					"KON = {\n",
					"    \"Män\": 1,\n",
					"    \"Kvinnor\": 2,\n",
					"    \"Båda könen\": 3\n",
					"}\n",
					"\n",
					"\n",
					"ATC_CHUNK, PER_PAGE = 20, 5000\n",
					"RETRY, BACKOFF, TIMEOUT, SLEEP = 4, 1.5, 60, 0.1\n",
					"\n",
					"# Ny, ren mapp \n",
					"OUT_DIR = \"out_diabetes_a10_clean\"\n",
					"os.makedirs(OUT_DIR, exist_ok=True)\n",
					"\n",
					"\n",
					"def get(url):\n",
					"    err=None\n",
					"    for i in range(1, RETRY+1):\n",
					"        try:\n",
					"            r=requests.get(url, headers=HEADERS, timeout=TIMEOUT)\n",
					"            if r.status_code==200: return r.json()\n",
					"            if r.status_code in (429,500,502,503,504): time.sleep(BACKOFF**i); continue\n",
					"            r.raise_for_status()\n",
					"        except Exception as e:\n",
					"            err=e; time.sleep(BACKOFF**i)\n",
					"    raise RuntimeError(f\"API-fel: {err} @ {url}\")\n",
					"\n",
					"def fetch_all(url):  # följ nasta_sida\n",
					"    data_all=[]; seen=set()\n",
					"    while url and url not in seen:\n",
					"        seen.add(url)\n",
					"        js=get(url)\n",
					"        items=js.get(\"data\", js) if isinstance(js,dict) else js\n",
					"        if not items: break\n",
					"        data_all += items\n",
					"        url = (js.get(\"nasta_sida\") or js.get(\"nästa_sida\") or js.get(\"next\")) if isinstance(js,dict) else None\n",
					"        time.sleep(SLEEP)\n",
					"    return data_all\n",
					"\n",
					"def list_atc_a10_leaf():\n",
					"    items = fetch_all(f\"{BASE}/atc?per_sida={PER_PAGE}\")\n",
					"    out=set()\n",
					"    for it in items:\n",
					"        code = it.get(\"id\") or it.get(\"atc\") or it.get(\"kod\")\n",
					"        if not code: continue\n",
					"        code = str(code).strip().upper()\n",
					"        if code.startswith(\"A10\") and len(code)==7:   # fulla koder (t.ex. A10AB01)\n",
					"            out.add(code)\n",
					"    return sorted(out)\n",
					"\n",
					"def list_years():\n",
					"    items=fetch_all(f\"{BASE}/ar?per_sida={PER_PAGE}\")\n",
					"    yrs=[]\n",
					"    for it in items:\n",
					"        y = it.get(\"id\") or it.get(\"ar\") or it.get(\"år\") or it.get(\"year\")\n",
					"        if y is not None:\n",
					"            yrs.append(int(y))\n",
					"    return sorted(set(yrs))\n",
					"\n",
					"def list_regions(include_riket=True):\n",
					"    items=fetch_all(f\"{BASE}/region?per_sida={PER_PAGE}\")\n",
					"    regs=sorted({int(it.get(\"id\")) for it in items if it.get(\"id\") is not None})\n",
					"    return ([0]+regs) if include_riket and 0 not in regs else regs\n",
					"\n",
					"def chunks(lst,n):\n",
					"    for i in range(0,len(lst),n): yield lst[i:i+n]\n",
					"\n",
					"def build_url(matt, atc_list, region, kon, years):\n",
					"    return (f\"{BASE}/resultat/matt/{matt}\"\n",
					"            f\"/atc/{quote(','.join(atc_list),safe=',')}\"\n",
					"            f\"/region/{region}/kon/{kon}\"\n",
					"            f\"/ar/{quote(','.join(map(str,years)),safe=',')}\"\n",
					"            f\"?per_sida={PER_PAGE}\")\n",
					"\n",
					"def to_num(s):\n",
					"    if s.dtype=='O':\n",
					"        s = s.str.replace(r\"\\s\",\"\",regex=True).str.replace(\"\\u00A0\",\"\",regex=False).str.replace(\",\",\".\",regex=False)\n",
					"    return pd.to_numeric(s, errors=\"coerce\")\n",
					"\n",
					"# ------------------ Hämtning per region ------------------\n",
					"def fetch_measure_region(matt, atc_codes, region, years):\n",
					"    rows=[]\n",
					"    for sex_label, kon_id in KON.items():\n",
					"        for atc_chunk in chunks(atc_codes, ATC_CHUNK):\n",
					"            url = build_url(matt, atc_chunk, region, kon_id, years)\n",
					"            for it in fetch_all(url):\n",
					"                #  nyckelhämtning från json\n",
					"                # år\n",
					"                year = it.get(\"ar\") if \"ar\" in it else (it.get(\"år\") or it.get(\"year\"))\n",
					"                # ATC-kod: i  \"atcId\"\n",
					"                atc  = it.get(\"atcId\") or it.get(\"atc\") or it.get(\"ATC\") or it.get(\"kod\") or it.get(\"code\")\n",
					"                # värde\n",
					"                value = it.get(\"varde\") or it.get(\"värde\") or it.get(\"value\") or it.get(\"antal\")\n",
					"\n",
					"                if atc is None:\n",
					"                    # hoppa över rader utan ATC, annars kollapsar det till 19*2=38 rader\n",
					"                    continue\n",
					"\n",
					"                rows.append({\n",
					"                    \"ar\": int(year) if year is not None else None,\n",
					"                    \"region\": region,\n",
					"                    \"kon\": kon_id,\n",
					"                    \"kon_label\": sex_label,\n",
					"                    \"atc\": str(atc),\n",
					"                    f\"matt_{matt}\": value\n",
					"                })\n",
					"    df = pd.DataFrame(rows)\n",
					"    if not df.empty:\n",
					"        df = df.drop_duplicates(subset=[\"ar\",\"region\",\"kon\",\"atc\",f\"matt_{matt}\"], keep=\"last\").reset_index(drop=True)\n",
					"    return df\n",
					"\n",
					"# ------------------ Körning ------------------\n",
					"print(\"Hämtar dimensioner…\")\n",
					"atc = list_atc_a10_leaf()\n",
					"years = list_years()\n",
					"regions = list_regions(True)\n",
					"print(f\"ATC (A10 fulla): {len(atc)} | År: {years[0]}–{years[-1]} | Kön: {list(KON.values())} | Regioner: {len(regions)}\")\n",
					"\n",
					"for region in regions:\n",
					"    tag=f\"region_{region}\"\n",
					"    pqt=f\"{OUT_DIR}/{tag}.parquet\"\n",
					"    csv=f\"{OUT_DIR}/{tag}.csv\"\n",
					"\n",
					"    if os.path.exists(pqt) or os.path.exists(csv):\n",
					"        print(f\"[SKIP] {tag}\")\n",
					"        continue\n",
					"\n",
					"    print(f\"[KÖR]  {tag} …\")\n",
					"    df_pat = fetch_measure_region(MATT_PAT, atc, region, years)\n",
					"    df_exp = fetch_measure_region(MATT_EXP, atc, region, years)\n",
					"\n",
					"    on=[\"ar\",\"region\",\"kon\",\"kon_label\",\"atc\"]\n",
					"    df = (pd.merge(df_pat, df_exp, on=on, how=\"outer\")\n",
					"            .rename(columns={f\"matt_{MATT_PAT}\":\"antal_patienter\",\n",
					"                             f\"matt_{MATT_EXP}\":\"antal_expedieringar\"}))\n",
					"\n",
					"    for c in (\"antal_patienter\",\"antal_expedieringar\"):\n",
					"        if c in df.columns: df[c]=to_num(df[c])\n",
					"\n",
					"    # dubbelsäkring: unika kombinationer år×region×kön×ATC\n",
					"    df = df.drop_duplicates(subset=on, keep=\"last\").sort_values(on).reset_index(drop=True)\n",
					"\n",
					"    try: df.to_parquet(pqt, index=False)\n",
					"    except: pass\n",
					"    df.to_csv(csv, index=False, encoding=\"utf-8\")\n",
					"\n",
					"    print(f\"[OK]   {tag} – rader: {len(df):,} | unika ATC: {df['atc'].nunique()}\")\n",
					"\n",
					"# ------------------ Slå ihop alla regioner ------------------\n",
					"dfs=[]\n",
					"for fp in sorted(glob.glob(f\"{OUT_DIR}/region_*.parquet\")):\n",
					"    try: dfs.append(pd.read_parquet(fp))\n",
					"    except: pass\n",
					"if not dfs:\n",
					"    for fp in sorted(glob.glob(f\"{OUT_DIR}/region_*.csv\")):\n",
					"        dfs.append(pd.read_csv(fp))\n",
					"\n",
					"final = pd.concat(dfs, ignore_index=True) if dfs else pd.DataFrame()\n",
					"print(\"TOTALA RADER:\", len(final))\n",
					"\n",
					"final_out_csv = f\"{OUT_DIR}/diabetes_A10_M_K_ALLA_regioner_ALLA_ar.csv\"\n",
					"final_out_parq = f\"{OUT_DIR}/diabetes_A10_M_K_ALLA_regioner_ALLA_ar.parquet\"\n",
					"final.to_csv(final_out_csv, index=False, encoding=\"utf-8\")\n",
					"try: final.to_parquet(final_out_parq, index=False)\n",
					"except: pass\n",
					"\n",
					"if not final.empty:\n",
					"    try:\n",
					"        print(\"År:\", int(final['ar'].min()), \"–\", int(final['ar'].max()),\n",
					"              \"| ATC:\", final['atc'].nunique(),\n",
					"              \"| Regioner:\", final['region'].nunique(),\n",
					"              \"| Kön:\", sorted(final['kon'].unique().tolist()))\n",
					"    except: pass\n",
					"\n",
					"print(\"Klart.\")\n",
					""
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"\n",
					"final_csv = f\"{OUT_DIR}/diabetes_A10_M_K_ALLA_regioner_ALLA_ar.csv\"\n",
					"\n",
					"df = pd.read_csv(final_csv)\n",
					"print(df.shape)            # (rader, kolumner)\n",
					"df.head(20)                # första 20 raderna\n",
					""
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"import os\n",
					"\n",
					"OUT_DIR   = \"out_diabetes_a10_clean\"  \n",
					"local_csv  = f\"{OUT_DIR}/diabetes_A10_M_K_ALLA_regioner_ALLA_ar.csv\"\n",
					"local_parq = f\"{OUT_DIR}/diabetes_A10_M_K_ALLA_regioner_ALLA_ar.parquet\"\n",
					"\n",
					"account   = \"group3fpadls\"\n",
					"container = \"group3fpfilesystem\"      \n",
					"folder    = \"staging\"                  \n",
					"\n",
					"target_base = f\"abfss://{container}@{account}.dfs.core.windows.net/{folder}\"\n",
					"mssparkutils.fs.mkdirs(target_base)\n",
					"\n",
					"# CSV -> staging/sweden_medical.csv\n",
					"mssparkutils.fs.cp(f\"file:{os.path.abspath(local_csv)}\",\n",
					"                   f\"{target_base}/sweden_medical.csv\",\n",
					"                   recurse=False)\n",
					"\n",
					"# Parquet -> staging/sweden_medical.parquet (om den finns)\n",
					"if os.path.exists(local_parq):\n",
					"    mssparkutils.fs.cp(f\"file:{os.path.abspath(local_parq)}\",\n",
					"                       f\"{target_base}/sweden_medical.parquet\",\n",
					"                       recurse=False)\n",
					"\n",
					"print(\"Uppladdat till:\")\n",
					"print(f\"{target_base}/sweden_medical.csv\")\n",
					"if os.path.exists(local_parq):\n",
					"    print(f\"{target_base}/sweden_medical.parquet\")\n",
					""
				],
				"execution_count": 22
			},
			{
				"cell_type": "code",
				"source": [
					"# Läs staging-data (Bronze)\n",
					"staging_path = \"abfss://group3fpfilesystem@group3fpadls.dfs.core.windows.net/staging/sweden_medical.parquet\"\n",
					"df_staging = spark.read.parquet(staging_path)\n",
					"\n",
					"# Kolla schema\n",
					"df_staging.printSchema()\n",
					"\n",
					"# Unika könsvärden (numeriska ID:n)\n",
					"df_staging.select(\"kon\").distinct().show()\n",
					"\n",
					"# Unika könsvärden med text-label (om finns i staging)\n",
					"if \"kon_label\" in df_staging.columns:\n",
					"    df_staging.select(\"kon\", \"kon_label\").distinct().show()\n",
					""
				],
				"execution_count": 106
			}
		]
	}
}